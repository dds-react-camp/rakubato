import random
import os
import json
import re
import asyncio
import uuid
from typing import Dict, Any, Optional, List
from datetime import datetime, timedelta, timezone

import vertexai
from vertexai.generative_models import GenerativeModel, Tool, FunctionDeclaration, Part
from vertexai.preview.vision_models import ImageGenerationModel

from google.cloud import storage
from google.oauth2 import service_account
from google.auth import default, impersonated_credentials
from googleapiclient.discovery import build
from google import genai
from google.genai import types as genai_types
from urllib.parse import urlparse

from app.schemas.product import Product
from app.core.config import settings

# Define the function declarations
navigate_func = FunctionDeclaration(
    name="navigate",
    description="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®æ–°ã—ã„ç”»é¢ã«é·ç§»ã•ã›ã¾ã™ã€‚",
    parameters={
        "type": "object",
        "properties": {
            "path": {
                "type": "string",
                "description": "é·ç§»å…ˆã®ãƒ‘ã‚¹ã€‚ä¾‹: /comparison, /products/p123"
            }
        },
        "required": ["path"]
    },
)

youtube_search_func = FunctionDeclaration(
    name="search_youtube_videos",
    description="YouTubeã§å‹•ç”»ã‚’æ¤œç´¢ã—ã¾ã™ã€‚",
    parameters={
        "type": "object",
        "properties": {
            "query": {
                "type": "string",
                "description": "YouTubeã§æ¤œç´¢ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€‚æ—¥æœ¬èªã§æŒ‡å®šã—ã¾ã™ã€‚"
            }
        },
        "required": ["query"]
    }
)

class AnalyzeNeedsService:
    def __init__(self, project_id: str, location: str):
        self.project_id = project_id
        self.location = location

        # Explicitly create credentials from the service account file if provided
        self.credentials = None
        if settings.GOOGLE_APPLICATION_CREDENTIALS:
            try:
                self.credentials = service_account.Credentials.from_service_account_file(
                    settings.GOOGLE_APPLICATION_CREDENTIALS
                )
            except Exception as e:
                print(f"ERROR: Failed to create credentials from file specified in GOOGLE_APPLICATION_CREDENTIALS: {e}")

        vertexai.init(project=self.project_id, location=self.location, credentials=self.credentials)
        
        # Initialize clients with credentials
        self.storage_client = storage.Client(credentials=self.credentials)
        if settings.YOUTUBE_API_KEY:
            self.youtube = build("youtube", "v3", developerKey=settings.YOUTUBE_API_KEY)
        else:
            self.youtube = None

        # Initialize the client for Google AI (for Veo)
        try:
            self.genai_client = genai.Client(
                project=self.project_id, 
                location=self.location, 
                vertexai=True
            )
        except Exception as e:
            print(f"ERROR: Failed to initialize genai.Client: {e}")
            self.genai_client = None

        # Combine tools
        combined_tool = Tool(function_declarations=[navigate_func, youtube_search_func])

        # Let the model know about the tools it can use
        self.model = GenerativeModel(
            "gemini-2.5-flash", 
            tools=[combined_tool]
        )

    def _search_youtube(self, query: str) -> List[Dict[str, Any]]:
        """Performs a YouTube search and returns video details."""
        if not self.youtube:
            return [{"error": "YouTube API key is not configured."}]
        try:
            search_response = self.youtube.search().list(
                q=query,
                part="snippet",
                type="video",
                maxResults=5,
                regionCode="JP",
                relevanceLanguage="ja"
            ).execute()

            videos = []
            for item in search_response.get("items", []):
                videos.append({
                    "title": item["snippet"]["title"],
                    "videoId": item["id"]["videoId"],
                    "channelTitle": item["snippet"]["channelTitle"],
                })
            return videos
        except Exception as e:
            print(f"Error searching YouTube: {e}")
            return []

    async def generate_chat_response(
        self, 
        message: str, 
        context: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """Generates a chat response using the Vertex AI Gemini API."""
        try:
            prompt = f'''
                # å‘½ä»¤æ›¸

                ã‚ãªãŸã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³¼å…¥æ´»å‹•ã‚’æ”¯æ´ã™ã‚‹å„ªç§€ãªã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚
                ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå…¥åŠ›ã—ãŸæ¤œè¨ä¸­ã®å•†å“ã«ã¤ã„ã¦ã€YouTubeã®ãƒ¬ãƒ“ãƒ¥ãƒ¼å‹•ç”»ã‚’å¤šè§’çš„ã«èª¿æŸ»ãƒ»åˆ†æã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè‡ªèº«ã®ãƒ‹ãƒ¼ã‚ºã«åˆã£ãŸæœ€é©ãªå•†å“ã‚’é¸ã¹ã‚‹ã‚ˆã†ã«ã‚µãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„ã€‚

                å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—:


                1.  **ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å—ã‘å–ã‚Š**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰å•†å“åã‚„ã‚«ãƒ†ã‚´ãƒªã‚’å—ã‘å–ã‚Šã¾ã™ã€‚
                2.  **YouTubeã§ã®å‹•ç”»æ¤œç´¢**: `search_youtube_videos` ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦ã€é–¢é€£æ€§ã®é«˜ã„ãƒ¬ãƒ“ãƒ¥ãƒ¼å‹•ç”»ã‚’æ¤œç´¢ã—ã¾ã™ã€‚æ¤œç´¢ã‚¯ã‚¨ãƒªã¯å…·ä½“çš„ã«ã€ä¾‹ãˆã°ã€Œ[å•†å“å] ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€ã®ã‚ˆã†ã«ã—ã¾ã™ã€‚
                3.  **ãƒ¬ãƒ“ãƒ¥ãƒ¼å‹•ç”»ã®åˆ†æ**: (ã“ã‚Œã¯æ¦‚å¿µçš„ãªã‚¹ãƒ†ãƒƒãƒ—ã§ã™ã€‚å®Ÿéš›ã«å‹•ç”»ã‚’è¦–è´ã™ã‚‹ã‚ã‘ã§ã¯ã‚ã‚Šã¾ã›ã‚“) æ¤œç´¢çµæœã®å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ã‚„ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‹ã‚‰ã€ãã®å‹•ç”»ãŒè‚¯å®šçš„ãªæ„è¦‹ã‹ã€å¦å®šçš„ãªæ„è¦‹ã‹ã€ã‚ã‚‹ã„ã¯ä¸­ç«‹çš„ãªæ¯”è¼ƒãƒ¬ãƒ“ãƒ¥ãƒ¼ãªã®ã‹ã‚’åˆ¤æ–­ã—ã¾ã™ã€‚
                4.  **æƒ…å ±ã®çµ±åˆã¨è¦ç´„**: è¤‡æ•°ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼å‹•ç”»ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸæƒ…å ±ã‚’çµ±åˆã—ã€å„å•†å“ã®é•·æ‰€ã¨çŸ­æ‰€ã‚’å®¢è¦³çš„ã«ã¾ã¨ã‚ã¦ã€ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚ºã—ã¾ã™ã€‚
                5.  **æœ€çµ‚çš„ãªææ¡ˆ**: åˆ†æçµæœã«åŸºã¥ã„ã¦ã€æ±‚ã‚ã‚‹å•†å“ã‚¿ã‚¤ãƒ—ã‚’ææ¡ˆã—ã¾ã™ã€‚
                ---

                {{ä»¥ä¸‹ã¯ã‚¤ãƒ³ãƒ—ãƒƒãƒˆã¨ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã®ä¾‹ã§ã‚ã‚Šã€å®Ÿéš›ã®å›ç­”ã«å«ã‚ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚}}

                ### å…·ä½“çš„ãªãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ä¾‹

                ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ä¾‹:
                ã€Œã‚½ãƒ‹ãƒ¼ã®ãƒ˜ãƒƒãƒ‰ãƒ›ãƒ³ã€WH-1000XM5ã‚’è²·ãŠã†ã‹æ‚©ã‚“ã§ã„ã¾ã™ã€‚ã€

                ### å…·ä½“çš„ãªã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã®ä¾‹

                AIã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ä¾‹ï¼ˆéè¡¨ç¤ºï¼‰:
                *   YouTubeã§ã€ŒWH-1000XM5 ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€ã‚’æ¤œç´¢ã€‚
                *   è¤‡æ•°ã®å‹•ç”»ã‚’åˆ†æã€‚ã€Œãƒã‚¤ã‚ºã‚­ãƒ£ãƒ³ã‚»ãƒªãƒ³ã‚°ã¯æœ€å¼·ã‚¯ãƒ©ã‚¹ã€ã€ŒéŸ³è³ªã‚‚è‰¯ã„ãŒã€ã‚‚ã£ã¨éŸ³æ¥½é‘‘è³ã«ç‰¹åŒ–ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚‚ã‚ã‚‹ã€ã€Œä¾¡æ ¼ãŒé«˜ã„ã€ã€ŒBoseã‚„SennheiserãŒç«¶åˆã¨ã—ã¦ã‚ˆãæŒ™
                ã’ã‚‰ã‚Œã‚‹ã€ã€Œè£…ç€æ„Ÿã‚„æºå¸¯æ€§ã‚‚é‡è¦ãªæ¯”è¼ƒãƒã‚¤ãƒ³ãƒˆã€ã¨ã„ã£ãŸæƒ…å ±ã‚’å¾—ã‚‹ã€‚
                *   ã“ã‚Œã‚‰ã®æƒ…å ±ã‹ã‚‰ã€ã€Œãƒã‚¤ã‚ºã‚­ãƒ£ãƒ³ã‚»ãƒªãƒ³ã‚°æ€§èƒ½ã€ã€ŒéŸ³è³ªã€ã€Œã‚³ã‚¹ãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€ã€Œæºå¸¯æ€§ã€ã¨ã„ã£ãŸé¸ã³æ–¹ã®è»¸ã‚’æŠ½å‡ºã™ã‚‹ã€‚


                AIã®æœ€çµ‚çš„ãªã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆä¾‹ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®æç¤ºå†…å®¹ï¼‰:
                ã€Œæ‰¿çŸ¥ã„ãŸã—ã¾ã—ãŸã€‚ã‚½ãƒ‹ãƒ¼ã®WH-1000XM5ã§ã™ã­ã€‚æ§˜ã€…ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æ‹è¦‹ã—ãŸã¨ã“ã‚ã€ç´ æ™´ã‚‰ã—ã„è£½å“ã§ã™ãŒã€è³¼å…¥ã•ã‚ŒãŸæ–¹ãŒã©ã®ã‚ˆã†ãªç‚¹ã‚’é‡è¦–ã™ã‚‹ã‹ã«ã‚ˆã£ã¦ã€ã•ã‚‰ã«æº€è¶³åº¦ã®
                é«˜ã„é¸æŠè‚¢ãŒã‚ã‚Šãã†ã§ã™ã€‚

                ã‚‚ã—ã‚ˆã‚ã—ã‘ã‚Œã°ã€ã‚ãªãŸãŒãƒ˜ãƒƒãƒ‰ãƒ›ãƒ³ã«æœ€ã‚‚æ±‚ã‚ã‚‹ã€Œæ–¹å‘æ€§ã€ã¯ä»¥ä¸‹ã®ã©ã‚Œã«è¿‘ã„ã‹æ•™ãˆã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿã€


                A. é™å¯‚æ€§ã‚’æœ€å„ªå…ˆã™ã‚‹ã‚¿ã‚¤ãƒ—: ã¨ã«ã‹ãå‘¨å›²ã®é¨’éŸ³ã‚’æ¶ˆã™ã“ã¨ã‚’æœ€å„ªå…ˆã—ã€æ¥­ç•Œæœ€é«˜ãƒ¬ãƒ™ãƒ«ã®ãƒã‚¤ã‚ºã‚­ãƒ£ãƒ³ã‚»ãƒªãƒ³ã‚°æ€§èƒ½ã‚’æ±‚ã‚ã‚‹ã€‚


                B. éŸ³è³ªã‚’æœ€å„ªå…ˆã™ã‚‹ã‚¿ã‚¤ãƒ—:
                ãƒã‚¤ã‚ºã‚­ãƒ£ãƒ³ã‚»ãƒªãƒ³ã‚°æ€§èƒ½ã‚‚é‡è¦ã ãŒã€ãã‚Œä»¥ä¸Šã«éŸ³æ¥½ã¸ã®æ·±ã„æ²¡å…¥æ„Ÿã‚„ã€ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã®æ¯é£ã„ã¾ã§æ„Ÿã˜ã‚‰ã‚Œã‚‹ã‚ˆã†ãªç¹Šç´°ãªéŸ³ã®è¡¨ç¾åŠ›ã‚’é‡è¦–ã™ã‚‹ã€‚


                C. ãƒãƒ©ãƒ³ã‚¹ã¨æºå¸¯æ€§ã‚’é‡è¦–ã™ã‚‹ã‚¿ã‚¤ãƒ—: é«˜ã„æ€§èƒ½ã¯ç¶­æŒã—ã¤ã¤ã€æ—¥å¸¸çš„ã«é•·æ™‚é–“åˆ©ç”¨ã—ã¦ã‚‚ç–²ã‚Œã«ãã„è»½ã•ã‚„ã€ã‚«ãƒãƒ³ã«ã™ã£ãã‚Šåã¾ã‚‹ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã•ã‚‚åŒã˜ãã‚‰ã„å¤§åˆ‡ã«ã™ã‚‹ã€‚

                D. ã‚³ã‚¹ãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é‡è¦–ã™ã‚‹ã‚¿ã‚¤ãƒ—: æœ€æ–°ãƒ»æœ€é«˜ã®æ©Ÿèƒ½ã«ã¯ã“ã ã‚ã‚‰ãšã€ååˆ†ãªæ€§èƒ½ã‚’æŒã¡ãªãŒã‚‰ã‚‚ã€ä¾¡æ ¼ã¨ã®ãƒãƒ©ãƒ³ã‚¹ãŒå–ã‚ŒãŸè³¢ã„é¸æŠã‚’ã—ãŸã„ã€‚
                ---
                ã§ã¯ã€å§‹ã‚ã¾ã—ã‚‡ã†ã€‚ç§ãŒæœ€åˆã«ãŠé¡˜ã„ã—ãŸã„å•†å“ã¯ã“ã¡ã‚‰ã§ã™ï¼š
                {message}
                '''
            
            chat = self.model.start_chat()
            response = await chat.send_message_async(prompt)
            
            res_text = ""
            res_nav = None

            for part in response.candidates[0].content.parts:
                if part.function_call:
                    if part.function_call.name == "navigate":
                        res_nav = part.function_call.args.get("path")
                    elif part.function_call.name == "search_youtube_videos":
                        query = part.function_call.args.get("query")
                        search_results = self._search_youtube(query)
                        
                        # Send search results back to the model
                        response = await chat.send_message_async(
                            Part.from_function_response(
                                name="search_youtube_videos",
                                response={
                                    "content": {"videos": search_results},
                                }
                            )
                        )
                        # Process the new response after providing tool output
                        for new_part in response.candidates[0].content.parts:
                            if hasattr(new_part, 'text') and new_part.text:
                                res_text += new_part.text

                elif hasattr(part, 'text') and part.text:
                    res_text += part.text
            
            if res_nav and not res_text:
                res_text = f"{res_nav} ã«ç§»å‹•ã—ã¾ã™ã€‚"

            return {"message": res_text, "navigateTo": res_nav}

        except Exception as e:
            print(f"Error calling Vertex AI: {e}")
            return {"message": "AIã¨ã®æ¥ç¶šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚", "navigateTo": None}

    async def _analyze_user_needs(self, product_category: str) -> dict:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ½œåœ¨çš„ãªãƒ‹ãƒ¼ã‚ºã‚’åˆ†æã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¿ã‚¤ãƒ—ã‚’æç¤ºã™ã‚‹"""
        print(f"[åˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] ã‚«ãƒ†ã‚´ãƒªã€Œ{product_category}ã€ã®æ½œåœ¨ãƒ‹ãƒ¼ã‚ºã‚’åˆ†æä¸­...")
        try:
            # Use a model without function calling for this specific task
            model = GenerativeModel("gemini-2.5-flash")
            prompt = f'''ã‚ãªãŸã¯ã€é¡§å®¢ã®æ½œåœ¨çš„ãªãƒ‹ãƒ¼ã‚ºã‚’åˆ†æã—ã€å…·ä½“çš„ãªå•†å“ã‚’ä¾‹ç¤ºã™ã‚‹ãƒ—ãƒ­ã®ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚

é¡§å®¢ãŒã€Œ{product_category}ã€ã®è³¼å…¥ã‚’æ¤œè¨ã—ã¦ã„ã¾ã™ã€‚

é¡§å®¢ãŒè‡ªèº«ã®å¥½ã¿ã‚’ç†è§£ã§ãã‚‹ã‚ˆã†ã«ã€é¸æŠã®è»¸ã¨ãªã‚‹ã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¿ã‚¤ãƒ—ã€ã‚’4ã€œ5ã¤æç¤ºã—ã¦ãã ã•ã„ã€‚
å„ã‚¿ã‚¤ãƒ—ã«ã¯ã€ãã®ç‰¹å¾´ã‚’è¡¨ã™ã‚¿ã‚°ã¨ã€ãã®ã‚¿ã‚¤ãƒ—ã‚’ä»£è¡¨ã™ã‚‹å…·ä½“çš„ãªå•†å“åã‚’1ã€œ3å€‹ä¾‹ç¤ºã—ã¦ãã ã•ã„ã€‚

çµæœã¯ã€å¿…ãšä»¥ä¸‹ã®JSONã‚¹ã‚­ãƒ¼ãƒã«å¾“ã£ãŸå˜ä¸€ã®JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

ã€å‡ºåŠ›JSONã‚¹ã‚­ãƒ¼ãƒã€‘
{{
  "user_archetypes": [
    {{
      "id": "ãƒ©ãƒ³ãƒ€ãƒ ãªãƒ¦ãƒ‹ãƒ¼ã‚¯IDæ–‡å­—åˆ—",  # UUIDã®ã‚ˆã†ãªãƒ©ãƒ³ãƒ€ãƒ ãªæ–‡å­—åˆ—
      "name": "æºå¸¯æ€§é‡è¦–ã‚¿ã‚¤ãƒ—", 
      "description": "ã‚«ãƒ•ã‚§ã‚„å‡ºå¼µå…ˆãªã©ã€ã©ã“ã¸ã§ã‚‚æŒã¡é‹ã³ãŸã„ã€‚è»½ã•ã¨è–„ã•ã‚’æœ€å„ªå…ˆã™ã‚‹ã‚ãªãŸã¸ã€‚", 
      "characteristics": ["è»½é‡", "è–„å‹", "é•·æ™‚é–“ãƒãƒƒãƒ†ãƒªãƒ¼"],
      "sampleProducts": ["HP Pavilion Aero 13-bg", "MacBook Air"]
    }}
  ]
}}'''

            response = await model.generate_content_async([prompt])
            
            if not response or not response.text:
                raise ValueError("AIãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç©ºã®å¿œç­”ãŒè¿”ã•ã‚Œã¾ã—ãŸã€‚")

            response_text = response.text.strip()
            # Find the start and end of the JSON object
            start_index = response_text.find('{')
            end_index = response_text.rfind('}')
            
            if start_index != -1 and end_index != -1:
                json_string = response_text[start_index:end_index+1]
            else:
                json_string = response_text

            try:
                json_response = json.loads(json_string)
            except json.JSONDecodeError as e:
                raise ValueError(f"AIãƒ¢ãƒ‡ãƒ«ã®å¿œç­”ã‚’JSONã¨ã—ã¦è§£æã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ç”Ÿã®å¿œç­”: {response_text}") from e

            print(f"[åˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
            return json_response

        except Exception as e:
            raise ValueError(f"åˆ†æä¸­ã«äºˆæœŸã›ã¬å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    async def _generate_image_prompts_async(self, product_description: str) -> dict:
        """Generates optimized prompts for image generation."""
        def get_policy_text():
            """Mock tool to get policy text."""
            return """å•†æ¨™ã€å€‹äººç‰¹å®šã€ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–ãªè¡¨ç¾ã¯é¿ã‘ã¦ãã ã•ã„ã€‚"""

        get_policy_text_tool = FunctionDeclaration(
            name="get_policy_text",
            description="ç”»åƒç”Ÿæˆã§éµå®ˆã™ã¹ããƒ«ãƒ¼ãƒ«ã‚’å–å¾—ã—ã¾ã™ã€‚",
            parameters={
                "type": "object",
                "properties": {}
            }
        )

        model = GenerativeModel(
            "gemini-2.0-flash-lite-001",
            tools=[Tool([get_policy_text_tool])]
        )

        chat = model.start_chat()

        prompt = f'''ã‚ãªãŸã®ä¸»ç›®çš„ï¼šå…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€Œã‚³ãƒãƒ¼ã‚¹ã‚µã‚¤ãƒˆã®å•†å“ç´¹ä»‹ã€ã«ä½¿ãˆã‚‹ã€
é«˜åº¦ã«ãƒ‡ãƒ•ã‚©ãƒ«ãƒ¡ã•ã‚ŒãŸæ¦‚å¿µã‚¤ãƒ©ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®
ã€Œãƒã‚¸ãƒ†ã‚£ãƒ–ï¼ˆç”Ÿæˆã—ãŸã„è¦ç´ ï¼‰ã€ã¨ã€Œãƒã‚¬ãƒ†ã‚£ãƒ–ï¼ˆé™¤å¤–ã—ãŸã„è¦ç´ ï¼‰ã€ã®
2ã¤ã®æœ€é©åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

å¿…é ˆæ‰‹é †ï¼ˆé †ã«å®Ÿè¡Œã™ã‚‹ã“ã¨ï¼‰:
1) æœ€åˆã« get_policy_text ãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã—ã¦ policy_text ã‚’å–å¾—ã—ã€ç”»åƒç”Ÿæˆã§éµå®ˆã™ã¹ããƒ«ãƒ¼ãƒ«ï¼ˆå•†æ¨™ã€å€‹äººç‰¹å®šã€ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–è¡¨ç¾ãªã©ï¼‰ã‚’æŠŠæ¡ã™ã‚‹ã€‚
2) å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿ã€ãã“ã‹ã‚‰è¡¨ç¾ã™ã¹ãã€Œæ¦‚å¿µã¨ã—ã¦ã®å•†å“ä¸»é¡Œï¼ˆprimary subjectï¼‰ã€ã‚’æŠ½å‡ºã¾ãŸã¯æ¦‚å¿µåŒ–ã™ã‚‹ã€‚ä¸»é¡Œã¯å¿…ãšä»¥ä¸‹ã‚’æº€ãŸã™ã“ã¨:
   - å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã®ç‰¹å¾´ï¼ˆä¾‹: ã‚¹ã‚¿ã‚¤ãƒªãƒƒã‚·ãƒ¥ã€ã‚·ãƒ³ãƒ—ãƒ«ãªæ“ä½œã€ç›´æ„Ÿçš„ãªUXã€å¹´é½¢å±¤ã¸ã®è¨´æ±‚ãªã©ï¼‰ã‚’è¦–è¦šçš„ã«å¼·èª¿ã—ã¦è¡¨ç¾ã§ãã‚‹ã“ã¨ã€‚æ¼«ç”»é¢¨ã®ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã‚„ã‚·ãƒ³ãƒœãƒ«ã‚’æ´»ç”¨ã—ã¦ã‚‚ã‚ˆã„ã€‚
   - ç‰¹å®šãƒ–ãƒ©ãƒ³ãƒ‰ã‚„å®Ÿåœ¨ã®å€‹äººã‚’é€£æƒ³ã•ã›ãªã„ï¼ˆéç‰¹å®šåŒ–ï¼‰ã“ã¨
   - ã‚³ãƒãƒ¼ã‚¹å‘ã‘ã«é­…åŠ›çš„ã§ã‚¯ãƒªãƒƒã‚¯ã•ã‚Œã‚„ã™ã„è¡¨ç¾ï¼ˆã‹ã‚ã„ã„3Dã€ã‚„ã‚ã‚‰ã‹ã„é›°å›²æ°—ï¼‰ã§ã‚ã‚‹ã“ã¨
3) ä¸»é¡Œã‚’åŸºã«ã€ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆã™ã‚‹ã€‚å¿…ãšä»¥ä¸‹ã‚’å«ã‚ã‚‹:
   - ãƒ‡ãƒ•ã‚©ãƒ«ãƒ¡åº¦åˆã„ã¯ã€Œã‹ã‚ã„ã„3Dã‚¢ãƒ‹ãƒ¡ã€ã‚¹ã‚¿ã‚¤ãƒ«ã§ã€ã‚„ã‚ã‚‰ã‹ã„è³ªæ„Ÿã¨æ˜ã‚‹ã„è‰²ä½¿ã„ã‚’åŸºæœ¬ã¨ã™ã‚‹ã“ã¨
   - ä¸»ãªè¦–è¦šè¦ç´ ï¼ˆå•†å“æ¦‚å¿µã®è±¡å¾´çš„ãªãƒ¢ãƒãƒ¼ãƒ•ã€ã‚·ãƒ³ãƒ—ãƒ«åŒ–ã•ã‚ŒãŸã‚¹ã‚¤ãƒƒãƒè¡¨ç¾ã€ç¬‘é¡”ã®éç‰¹å®šäººç‰©ãªã©ï¼‰
   - è‰²èª¿ã¨ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆï¼ˆã‚„ã‚ã‚‰ã‹ã„ãƒ‘ã‚¹ãƒ†ãƒ«ã‚«ãƒ©ãƒ¼ã‚’åŸºèª¿ã¨ã—ã€ã‚³ãƒãƒ¼ã‚¹ã§ç›®ã‚’å¼•ãé…è‰²ï¼‰ã€ä½™ç™½ï¼ˆãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸã‚’æƒ³å®šï¼‰
   - å‡ºåŠ›å…ˆãŒå•†å“ç´¹ä»‹ã§ã‚ã‚‹ã“ã¨ã‚’æ„è­˜ã—ãŸè§£åƒåº¦ãƒ»ãƒ‡ã‚£ãƒ†ãƒ¼ãƒ«æŒ‡ç¤ºï¼ˆé«˜è§£åƒåº¦ã€æ»‘ã‚‰ã‹ãªæ›²ç·šï¼‰
4) policy_text ã«åŸºã¥ããƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã¤ãã‚Šã€ç¦æ­¢è¦ç´ ã‚„æœ›ã¾ã—ããªã„è¡¨ç¾ï¼ˆç‰¹å®šãƒ–ãƒ©ãƒ³ãƒ‰ãƒ­ã‚´ã€è‘—åäººç‰©ã€éåº¦ãªè£¸ä½“ãƒ»æš´åŠ›ã€å€‹äººç‰¹å®šã«ã¤ãªãŒã‚‹é¡”ã®è©³ç´°ãªã©ï¼‰ã¨ç”Ÿæˆã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆï¼ˆã¼ã‚„ã‘ã€ã‚¦ã‚©ãƒ¼ã‚¿ãƒ¼ãƒãƒ¼ã‚¯ã€ä½è§£åƒåº¦ï¼‰ã‚’æ˜ç¤ºçš„ã«æ’é™¤ã™ã‚‹ã€‚
5) æœ€çµ‚å‡ºåŠ›ã¯ä»¥ä¸‹ã®JSONã‚¹ã‚­ãƒ¼ãƒã«å³å¯†ã«å¾“ã£ã¦è¿”ã™ã“ã¨ï¼ˆJSON ä»¥å¤–ã®èª¬æ˜ã‚’ä»˜ã‘ãªã„ï¼‰:

{{
  "subject": "<æŠ½å‡ºã—ãŸæ¦‚å¿µçš„ãªä¸»é¡Œï¼ˆçŸ­æ–‡ï¼‰>",
  "positive_prompt": "<Imagen ç”¨ã«æœ€é©åŒ–ã•ã‚ŒãŸæ—¥æœ¬èª/è‹±èªã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆå•†å“ã®ã‚¹ã‚¿ã‚¤ãƒ«ã€è‰²ã€æ§‹å›³ã€è³ªæ„Ÿãªã©ã‚’è©³ç´°ã«è¨˜è¿°ï¼‰>",
  "negative_prompt": "<é™¤å¤–ã—ãŸã„è¦ç´ ã®åˆ—æŒ™ï¼ˆpolicy ã«åŸºã¥ãç¦æ­¢è¦ç´ ãƒ»ç”Ÿæˆã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆç­‰ï¼‰>",
  "composition": "<å•†å“ã®è¦‹ã›æ–¹ï¼šä¸­å¤®é…ç½®ã‹å·¦å¯„ã›ã‹ã€ä½™ç™½ã€ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã®æŒ‡å®š>",
  "style": "<ã‹ã‚ã„ã„3Dã‚¢ãƒ‹ãƒ¡ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆå›ºå®šï¼‰ã¨ã€ãƒˆãƒ¼ãƒ³ï¼ˆãƒãƒƒãƒ—/è½ã¡ç€ã„ãŸç­‰ï¼‰>",
  "policy_checks": "<policy_text ã«åŸºã¥ãç‰¹ã«æ³¨æ„ã—ãŸç‚¹ã®ç°¡æ½”ãªç®‡æ¡æ›¸ã>",
  "rationale": "<é¸æŠã—ãŸä¸»é¡Œãƒ»ã‚¹ã‚¿ã‚¤ãƒ«ãƒ»é™¤å¤–ç†ç”±ï¼ˆ1ï½2æ–‡ï¼‰>"
}}

å‡ºåŠ›ãƒ«ãƒ¼ãƒ«ï¼ˆå³å®ˆï¼‰:
- subject ã¯å…¥åŠ›ã«å¿ å®Ÿã§ç°¡æ½”ã«ï¼ˆæ¦‚å¿µã‚’ç¤ºã™çŸ­ã„ãƒ•ãƒ¬ãƒ¼ã‚ºï¼‰ã€‚
- positive_prompt ã¯ã€Œä¸€ç›®ã§ç‰¹å¾´ãŒåˆ†ã‹ã‚‹ã€ã“ã¨ã‚’æœ€å„ªå…ˆã«ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒ¡ã®åº¦åˆã„ãƒ»è¦–è¦šçš„è¨˜å·ï¼ˆç°¡ç•¥åŒ–ã•ã‚ŒãŸã‚¹ã‚¤ãƒƒãƒã€ç¬‘é¡”ã®éç‰¹å®šäººç‰©ã€ã‚¢ã‚¤ã‚³ãƒ³çš„ãªæ­¯ãƒ–ãƒ©ã‚·å½¢çŠ¶ãªã©ï¼‰ãƒ»é…è‰²ãƒ»ç…§æ˜ãƒ»ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ãƒ»ä½™ç™½æŒ‡ç¤ºã‚’ç››ã‚Šè¾¼ã‚€ã€‚
- negative_prompt ã¯ policy_text ã«åŸºã¥ãç‰¹å®šãƒ–ãƒ©ãƒ³ãƒ‰ã‚„å€‹äººãŒé€£æƒ³ã•ã‚Œã‚‹è¦ç´ ã€ç¾å®Ÿçš„ã™ãã‚‹å†™å®Ÿè¡¨ç¾ï¼ˆç‰¹å®šåŒ–ã‚’æ‹›ãï¼‰ã‚„NSFWãƒ»æš´åŠ›è¡¨ç¾ãƒ»ã‚¦ã‚©ãƒ¼ã‚¿ãƒ¼ãƒãƒ¼ã‚¯ãƒ»ç½²åãªã©ã‚’å¿…ãšé™¤å¤–ã™ã‚‹ã€‚è‹±èªä»¥å¤–ã®ãƒ†ã‚­ã‚¹ãƒˆã¯å…¥ã‚Œãªã„ã€‚
- composition ã¯ã‚³ãƒãƒ¼ã‚¹ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼ˆå•†å“ç”»åƒã®å‘ãã€å‚¾ãã€é…ç½®ã‚’è€ƒæ…®ï¼‰ã‚’æ˜ç¤ºã™ã‚‹ã€‚
- style ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒ¡æ–¹å¼ã¨æ„Ÿæƒ…çš„ãƒˆãƒ¼ãƒ³ï¼ˆä¾‹: ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ã§å®‰å¿ƒæ„Ÿã®ã‚ã‚‹ãƒãƒƒãƒ—ï¼‰ã‚’æ˜ç¤ºã™ã‚‹ã€‚
- policy_checks ã«ã¯ get_policy_text ã‹ã‚‰æŠœãå‡ºã—ãŸé‡è¦ãƒ«ãƒ¼ãƒ«ã¨ã€ãã‚Œã«å¯¾ã—ã¦ã©ã®ã‚ˆã†ã«å¯¾å¿œã—ãŸã‹ã‚’çŸ­ãè¨˜è¼‰ã™ã‚‹ã€‚
- è¿”ç­”ã¯ä½™è¨ˆãªèª¬æ˜ã‚’å«ã‚ãšã€ä¸Šè¨˜JSON ã®ã¿ã‚’è¿”ã™ã“ã¨ã€‚

ä¾‹ï¼ˆå‚è€ƒã€å®Ÿéš›ã®è¿”ç­”ã§ã¯ JSON ã®ã¿ã‚’å‡ºåŠ›ï¼‰:
{{
  "subject": "ä¸¸ã¿ã‚’ãŠã³ãŸã‹ã‚ã„ã„ãƒ•ã‚©ãƒ«ãƒ ã®ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã«è¡¨ç¤ºã•ã‚ŒãŸã€ã‚·ãƒ³ãƒ—ãƒ«ãªæ“ä½œã®ã‚¢ãƒ—ãƒªï¼ˆæ¦‚å¿µï¼‰",
  "positive_prompt": "A cute, friendly 3D character with big eyes, in a soft, pastel-colored world. The character is smiling and pointing to a simple, intuitive app interface on a smartphone screen. The style is clean, with soft lighting and a shallow depth of field. 3D rendered, high-resolution, vibrant, and cheerful.",
  "negative_prompt": "no brand logos, no identifiable faces, no photorealism, no complex details, no dark colors, no text overlays, no watermark, low-res, blurry, gore, nsfw",
  "composition": "ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã‚’ä¸­å¤®ã«é…ç½®ã—ã€è¦–ç·šãŒã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã®ç”»é¢ã«å‘ã‹ã†ã‚ˆã†ã«æ§‹å›³ã‚’èª¿æ•´ã€‚èƒŒæ™¯ã¯ã‚·ãƒ³ãƒ—ãƒ«ã§ã€ã‚¢ãƒ—ãƒªãŒéš›ç«‹ã¤ã‚ˆã†ã«ã™ã‚‹ã€‚",
  "style": "3D animation / soft and friendly tone",
  "policy_checks": "ãƒ–ãƒ©ãƒ³ãƒ‰ãƒ»äººç‰©ç‰¹å®šã‚’é¿ã‘ã‚‹ï¼ˆpolicy_text æº–æ‹ ï¼‰",
  "rationale": "è¦ªã—ã¿ã‚„ã™ã„3Dã‚¢ãƒ‹ãƒ¡é¢¨ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒ¡ã¨ã‚·ãƒ³ãƒ—ãƒ«ãªæ§‹æˆã§ã€ã‚¢ãƒ—ãƒªã®ä½¿ã„ã‚„ã™ã•ã¨æ¥½ã—ã•ã‚’è¦–è¦šçš„ã«ä¼ãˆã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ãŸã€‚"
}}

å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ: {product_description}
'''
        response = await chat.send_message_async(prompt)

        part = response.candidates[0].content.parts[0]

        if part.function_call:
            function_call = part.function_call
            if function_call.name == "get_policy_text":
                policy_text = get_policy_text()
                response = await chat.send_message_async(
                    Part.from_function_response(
                        name="get_policy_text",
                        response={
                            "content": policy_text,
                        }
                    ),
                )
                try:
                    response_text = response.text.strip()
                    match = re.search(r"```json\s*(\{.*\})\s*```", response_text, re.DOTALL)
                    if match:
                        response_text = match.group(1)
                    return json.loads(response_text)
                except (json.JSONDecodeError, AttributeError):
                    return {"error": "Failed to get valid JSON response from prompt generation agent after tool call."}
        
        try:
            response_text = response.text.strip()
            match = re.search(r"```json\s*(\{.*\})\s*```", response_text, re.DOTALL)
            if match:
                response_text = match.group(1)
            return json.loads(response_text)
        except (json.JSONDecodeError, AttributeError):
            return {"error": "Failed to get valid JSON response from prompt generation agent."}

    async def _generate_image_async(self, archetype: dict, session_id: str) -> Optional[str]:
        """ã‚¤ãƒ¡ãƒ¼ã‚¸ç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: å„ã‚¿ã‚¤ãƒ—ã‚’è±¡å¾´ã™ã‚‹å•†å“ã‚’ã€å˜è‰²ã®ã‚¤ãƒ©ã‚¹ãƒˆèª¿ã§ç”Ÿæˆã—ã€GCSã«ä¿å­˜ã™ã‚‹"""
        archetype_id = archetype.get("id", "unknown")
        print(f"[ç”»åƒç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] ã‚¿ã‚¤ãƒ—ID: {archetype_id} ã®ç”»åƒç”Ÿæˆã‚’é–‹å§‹...")
        try:
            product_description = archetype.get('description', 'a generic product')
            prompt_generation_result = await self._generate_image_prompts_async(product_description)

            if "error" in prompt_generation_result:
                print(f"[ç”»åƒç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {prompt_generation_result['error']}")
                return None

            image_prompt = prompt_generation_result.get("positive_prompt")
            if not image_prompt:
                print(f"[ç”»åƒç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
                return None

            model = ImageGenerationModel.from_pretrained("imagen-4.0-fast-generate-001")
            
            response = None
            max_retries = 3
            retry_delay = 2  # seconds
            for attempt in range(max_retries):
                try:
                    response = await asyncio.to_thread(
                        model.generate_images,
                        prompt=image_prompt,
                        number_of_images=1
                    )
                    if response and response.images:
                        break  # Success
                    else:
                        # This case handles when generate_images returns a response with no images, but doesn't throw an exception.
                        print(f"[ç”»åƒç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] ç”»åƒãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™... ({attempt + 1}/{max_retries})")
                        await asyncio.sleep(retry_delay)
                        retry_delay *= 2

                except Exception as e:
                    if "429" in str(e) and attempt < max_retries - 1:
                        print(f"[ç”»åƒç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] 429ãƒªã‚½ãƒ¼ã‚¹æ¯æ¸‡ã‚¨ãƒ©ãƒ¼ã€‚{retry_delay}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™... ({attempt + 1}/{max_retries})")
                        await asyncio.sleep(retry_delay)
                        retry_delay *= 2  # Exponential backoff
                    else:
                        # For other errors or last retry, print and return None
                        print(f"[ç”»åƒç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] ã‚¿ã‚¤ãƒ—ID: {archetype_id} ã®ç”»åƒç”Ÿæˆä¸­ã«å›å¾©ä¸èƒ½ãªã‚¨ãƒ©ãƒ¼: {e}")
                        return None # Exit and return None
            
            if not response or not response.images:
                print(f"[ç”»åƒç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] ã‚¿ã‚¤ãƒ—ID: {archetype_id} ã®ç”»åƒç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç”»åƒãŒè¿”ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
                return None

            image_bytes = response.images[0]._image_bytes
            
            bucket = self.storage_client.bucket(settings.GCS_BUCKET_NAME)
            blob_name = f"archetype_images/{session_id}/{archetype_id}.png"
            blob = bucket.blob(blob_name)
            
            await asyncio.to_thread(blob.upload_from_string, image_bytes, content_type='image/png')
            print(f"[ç”»åƒç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] ã‚¿ã‚¤ãƒ—ID: {archetype_id} ã®ç”»åƒã‚’GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ: gs://{settings.GCS_BUCKET_NAME}/{blob_name}")

            # Generate a signed URL to provide temporary access to the private object
            expiration_time = datetime.now() + timedelta(hours=1) 
            
            signing_creds = self.credentials

            if not signing_creds:
                if not settings.GCP_IAM_SERVICE_ACCOUNT_EMAIL:
                    raise ValueError("GCP_IAM_SERVICE_ACCOUNT_EMAIL is not set. It's required for signing URLs in this environment.")
                
                # Get default credentials from the environment
                default_creds, _ = default()
                # Create impersonated credentials
                signing_creds = impersonated_credentials.Credentials(
                    source_credentials=default_creds,
                    target_principal=settings.GCP_IAM_SERVICE_ACCOUNT_EMAIL,
                    target_scopes=["https://www.googleapis.com/auth/iam"], # Scope for signing
                )

            signed_url = await asyncio.to_thread(
                blob.generate_signed_url,
                expiration=expiration_time,
                credentials=signing_creds,
                version="v4"
            )
            
            print(f"[ç”»åƒç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] ã‚¿ã‚¤ãƒ—ID: {archetype_id} ã®ç½²åä»˜ãURLã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚")
            return signed_url

        except Exception as e:
            print(f"[ç”»åƒç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] ã‚¿ã‚¤ãƒ—ID: {archetype_id} ã®ç”»åƒç”Ÿæˆã¾ãŸã¯ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    async def analyze_needs_and_generate_images(self, product_category: str) -> Dict[str, Any]:
        """Orchestrates needs analysis and image generation."""
        session_id = str(uuid.uuid4())
        print(f"[ãƒ¡ã‚¤ãƒ³] ã‚»ãƒƒã‚·ãƒ§ãƒ³ID: {session_id}")

        try:
            analysis_result = await self._analyze_user_needs(product_category)
            
            archetypes = analysis_result.get("user_archetypes", [])
            if not archetypes:
                print("åˆ†æã®çµæœã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¿ã‚¤ãƒ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                return analysis_result

            print("\n[ãƒ¡ã‚¤ãƒ³] å„ã‚¿ã‚¤ãƒ—ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ç”»åƒã‚’ä¸¦åˆ—ã§ç”Ÿæˆã—ã€GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™...")
            # To avoid 429 Resource Exhausted errors, limit concurrent requests to the image generation API.
            sem = asyncio.Semaphore(3)

            async def generate_with_semaphore(archetype, session_id):
                async with sem:
                    return await self._generate_image_async(archetype, session_id)

            image_tasks = [generate_with_semaphore(archetype, session_id) for archetype in archetypes]
            signed_urls = await asyncio.gather(*image_tasks)

            for i, archetype in enumerate(archetypes):
                archetype["imageUrl"] = signed_urls[i]

            print("\n========================================")
            print(f"ğŸ†ã€Œ{product_category}ã€ã®åˆ†æçµæœ ğŸ†")
            print("========================================")
            print(json.dumps(analysis_result, indent=2, ensure_ascii=False))
            return analysis_result

        except Exception as e:
            print(f"\n[ãƒ¡ã‚¤ãƒ³] ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            raise e

    async def _get_video_view_counts_async(self, video_ids: list[str]) -> dict[str, int]:
        """YouTube Data APIã‚’ä½¿ã£ã¦ã€è¤‡æ•°ã®å‹•ç”»ã®å†ç”Ÿæ•°ã‚’ä¸€æ‹¬ã§å–å¾—ã™ã‚‹"""
        if not self.youtube:
            print("[è­¦å‘Š] YouTubeã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å†ç”Ÿæ•°ã¯0ã«ãªã‚Šã¾ã™ã€‚")
            return {video_id: 0 for video_id in video_ids}

        try:
            def fetch_views():
                request = self.youtube.videos().list(part="statistics", id=",".join(video_ids[:50]))
                response = request.execute()
                return {item['id']: int(item['statistics']['viewCount']) for item in response.get('items', [])}
            
            view_counts = await asyncio.to_thread(fetch_views)
            print(f"[YouTube] å†ç”Ÿæ•°ã‚’ä¸€æ‹¬å–å¾—ã—ã¾ã—ãŸ: {view_counts}")
            return view_counts
        except Exception as e:
            print(f"[è­¦å‘Š] YouTube APIã‹ã‚‰ã®å†ç”Ÿæ•°å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return {video_id: 0 for video_id in video_ids}

    async def _extract_product_info_from_video_async(self, youtube_link: str, limited_tags: List[str], keyword: str) -> tuple[str, dict]:
        """ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: å‹•ç”»ã‹ã‚‰è©³ç´°ãªå•†å“æƒ…å ±ã‚’æŠ½å‡ºã—ã€JSONå½¢å¼ã§ç”Ÿæˆã™ã‚‹"""
        print(f"[ãƒ¯ãƒ¼ã‚«ãƒ¼] {youtube_link} ã®å•†å“åˆ†æã‚’é–‹å§‹..." )
        try:
            model = GenerativeModel("gemini-2.0-flash")
            
            video_part_dict = {
                "file_data": {
                    "file_uri": youtube_link,
                    "mime_type": "video/youtube",
                },
            }

            video_metadata = {}
            if settings.VIDEO_ANALYSIS_START_OFFSET:
                video_metadata["start_offset"] = settings.VIDEO_ANALYSIS_START_OFFSET
            if settings.VIDEO_ANALYSIS_END_OFFSET:
                video_metadata["end_offset"] = settings.VIDEO_ANALYSIS_END_OFFSET
            
            if video_metadata:
                video_part_dict["video_metadata"] = video_metadata

            youtube_video = Part.from_dict(video_part_dict)

            # specificationsã®ã‚¹ã‚­ãƒ¼ãƒã‚’å‹•çš„ã«ç”Ÿæˆ
            specifications_schema_parts = []
            for tag in limited_tags:
                specifications_schema_parts.append(f'          "{tag}": "1ã‹ã‚‰5ã®5æ®µéšè©•ä¾¡ï¼ˆæ•´æ•°ï¼‰"')
            specifications_schema = "{\n" + ",\n".join(specifications_schema_parts) + "\n        }"

            prompt = f"""ã‚ãªãŸã¯ã€å‹•ç”»ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‹ã‚‰ç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹å•†å“ã®è©³ç´°æƒ…å ±ã‚’æ­£ç¢ºã«æŠ½å‡ºã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚

ä»¥ä¸‹ã®å‹•ç”»ã‚’åˆ†æã—ã€ã€Œ{keyword}ã€ã«é–¢é€£ã™ã‚‹å•†å“ã®ã¿ã‚’æŠ½å‡ºã—ã€ä¸‹è¨˜ã®JSONã‚¹ã‚­ãƒ¼ãƒã«å¾“ã£ã¦æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
ã€Œ{keyword}ã€ã¨é–¢é€£ã®ãªã„å•†å“ã¯ç„¡è¦–ã—ã¦ãã ã•ã„ã€‚

é‡è¦ãªæŒ‡ç¤º:
- `name`ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ã¯ã€å¿…ãšå…·ä½“çš„ãªè£½å“ãƒ»å•†å“åã‚’æŒ‡å®šã—ã¦ãã ã•ã„ï¼ˆä¾‹: "MacBook Air M2", "ã‚½ãƒ‹ãƒ¼ WH-1000XM5"ï¼‰ã€‚
- ã‚¹ãƒšãƒƒã‚¯æƒ…å ±ã‚’å«ã‚€ã‚ˆã†ãªä¸€èˆ¬çš„ãªèª¬æ˜ï¼ˆä¾‹: "é«˜æ€§èƒ½ãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³ (Intel Core Ultra 7 255H)"ï¼‰ã¯ã€`name`ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚
- `specs`ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ã¯ã€å‹•ç”»ã§è¨€åŠã•ã‚Œã¦ã„ã‚‹è£½å“ã®å…·ä½“çš„ãªã‚¹ãƒšãƒƒã‚¯æƒ…å ±ã‚’ã‚­ãƒ¼ã¨å€¤ã®ãƒšã‚¢ã§æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚é‡è¦ãªé …ç›®ï¼ˆä¾‹: æœ¬ä½“ã®ã‚µã‚¤ã‚ºãƒ»é‡é‡ã€ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤ã€ã‚«ãƒ¡ãƒ©æ€§èƒ½ã€ãƒãƒƒãƒ†ãƒªãƒ¼é§†å‹•æ™‚é–“ãªã©ï¼‰ã‚’ã§ãã‚‹ã ã‘å«ã‚ã¦ãã ã•ã„ã€‚

æƒ…å ±ãŒè¦‹ã¤ã‹ã‚‰ãªã„é …ç›®ã«ã¤ã„ã¦ã¯ã€`null`ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚
ç‰¹ã«ã€`specifications`ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å„é …ç›®ã¯ã€1ï¼ˆå…¨ãä¸æº€ï¼‰ã‹ã‚‰5ï¼ˆå¤§å¤‰æº€è¶³ï¼‰ã®5æ®µéšã®æ•´æ•°ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
**JSONã®æ§‹æ–‡ã€ç‰¹ã«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å„ã‚­ãƒ¼ã®å¾Œã«ã¯å¿…ãšã‚³ãƒ­ãƒ³(:)ã‚’è¨˜è¿°ã—ã€ãã®å¾Œã«å€¤ã‚’ç¶šã‘ã‚‹ãƒ«ãƒ¼ãƒ«ã‚’å³å®ˆã—ã¦ãã ã•ã„ã€‚**

ã€å‡ºåŠ›JSONã‚¹ã‚­ãƒ¼ãƒã€‘
{{
  "products": [
    {{
      "name": "å…·ä½“çš„ãªè£½å“åï¼ˆä¾‹: MacBook Air M2ï¼‰",
      "price": 12345, // æ•°å€¤ã€‚ä¸æ˜ãªå ´åˆã¯null
      "description": "å•†å“ã®ç°¡æ½”ãªèª¬æ˜",
      "specs": {{
        "æœ¬ä½“é‡é‡": "150g",
        "ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤": "6.1ã‚¤ãƒ³ãƒ Super Retina XDR",
        "é˜²æ°´é˜²å¡µ": "IP68ç­‰ç´š"
      }},
      "specifications": {specifications_schema},
      "category": "å•†å“ã®ã‚«ãƒ†ã‚´ãƒªï¼ˆä¾‹: smartphone, laptopï¼‰",
      "tags": ["ç‰¹å¾´ã‚’è¡¨ã™ã‚¿ã‚°1", "ã‚¿ã‚°2"]
    }}
  ]
}}
"""
            contents = [youtube_video, prompt]
            response = await model.generate_content_async(contents)
            
            if not response or not response.text:
                raise ValueError("AIãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç©ºã®å¿œç­”ãŒè¿”ã•ã‚Œã¾ã—ãŸã€‚ã‚»ãƒ¼ãƒ•ãƒ†ã‚£è¨­å®šã«ã‚ˆã‚‹ãƒ–ãƒ­ãƒƒã‚¯ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

            response_text = response.text.strip()
            json_string = response_text

            # Extract JSON from markdown block if present
            match = re.search(r"```json\s*(\{.*\})\s*```", response_text, re.DOTALL)
            if match:
                json_string = match.group(1)
            
            try:
                json_summary = json.loads(json_string)
            except json.JSONDecodeError:
                print(f"[ãƒ¯ãƒ¼ã‚«ãƒ¼] ERROR: JSONã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ¢ãƒ‡ãƒ«ã®ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹: '''{response_text}'''")
                raise ValueError("ãƒ¢ãƒ‡ãƒ«ãŒæœ‰åŠ¹ãªJSONã‚’è¿”ã—ã¾ã›ã‚“ã§ã—ãŸã€‚")

            print(f"[ãƒ¯ãƒ¼ã‚«ãƒ¼] {youtube_link} ã®å•†å“åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
            return youtube_link, json_summary

        except Exception as e:
            error_message = f"å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
            print(f"[ãƒ¯ãƒ¼ã‚«ãƒ¼] {youtube_link} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return youtube_link, {"error": error_message}

    async def _generate_final_recommendation_async(self, all_products: list) -> dict:
        """ç·æ‹¬ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: å…¨ãƒ¯ãƒ¼ã‚«ãƒ¼ã®çµæœã‚’åˆ†æã—ã€ãŠã™ã™ã‚å•†å“ã®ãƒªã‚¹ãƒˆã‚’JSONã§è¿”ã™"""
        print("[ç·æ‹¬ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] å…¨ãƒ¯ãƒ¼ã‚«ãƒ¼ã®åˆ†æçµæœã‚’è©•ä¾¡ã—ã€ãŠã™ã™ã‚å•†å“ã‚’ãƒ©ãƒ³ã‚¯ä»˜ã‘ä¸­...")
        try:
            if not all_products:
                return {"error": "æœ‰åŠ¹ãªåˆ†æçµæœãŒãªã‹ã£ãŸãŸã‚ã€ãŠã™ã™ã‚å•†å“ã‚’æ±ºå®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"}

            results_json_string = json.dumps(all_products, indent=2, ensure_ascii=False)
            model = GenerativeModel("gemini-2.5-flash-lite")
            prompt = f'''ã‚ãªãŸã¯è¤‡æ•°ã®å•†å“æƒ…å ±ãƒªã‚¹ãƒˆã‚’è©•ä¾¡ã—ã€è³¼å…¥æ¤œè¨è€…ã«æœ€é©ãªãŠã™ã™ã‚ã‚’ææ¡ˆã™ã‚‹ãƒãƒ¼ãƒ•ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚

ä»¥ä¸‹ã®JSONãƒ‡ãƒ¼ã‚¿ã¯ã€è¤‡æ•°ã®å‹•ç”»ã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸå•†å“æƒ…å ±ã®ãƒªã‚¹ãƒˆã§ã™ã€‚å„å•†å“ã«ã¯ã€æƒ…å ±ã‚½ãƒ¼ã‚¹ã¨ãªã£ãŸå‹•ç”»ã®URLãƒªã‚¹ãƒˆ(`source_urls`)ã¨ã€å„å‹•ç”»ã®å†ç”Ÿæ•°ãƒªã‚¹ãƒˆ(`source_review_counts`)ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚

{results_json_string}

ä¸Šè¨˜ã®æƒ…å ±å…¨ä½“ã‚’æ¯”è¼ƒæ¤œè¨ã—ã€ã‚¹ãƒšãƒƒã‚¯ã€ä¾¡æ ¼ã€ç‰¹å¾´ã€ãã—ã¦å‹•ç”»ã®å†ç”Ÿæ•°ã‚’äººæ°—åº¦ã®æŒ‡æ¨™ã¨ã—ã¦è€ƒæ…®ã—ã€ã€ŒãŠã™ã™ã‚ã§ãã‚‹å•†å“ã€ã‚’**æœ€å¤§10å€‹ã¾ã§**é¸ã‚“ã§ãã ã•ã„ã€‚
é¸ã‚“ã å„å•†å“ã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®å‡¦ç†ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
1. `id`: å…ƒã®å•†å“ã«å«ã¾ã‚Œã‚‹`id`ã‚’ãã®ã¾ã¾ç¶­æŒã—ã¦ãã ã•ã„ã€‚
2. `rating`: ã‚ãªãŸã®ç·åˆçš„ãªè©•ä¾¡ã‚’1ã€œ5ã®5æ®µéšè©•ä¾¡ï¼ˆæ•°å€¤ï¼‰ã§æ¡ç‚¹ã—ã¦ãã ã•ã„ã€‚
3. `reviewCount`: `source_review_counts` ã®**åˆè¨ˆå€¤**ã‚’ã“ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚
4. `source_urls`: `source_urls` ã®ãƒªã‚¹ãƒˆã‚’ãã®ã¾ã¾å«ã‚ã¦ãã ã•ã„ã€‚
5. `recommendation_reason`: ãªãœãã®å•†å“ãŒãŠã™ã™ã‚ãªã®ã‹ã‚’èª¬æ˜ã™ã‚‹æ–‡ç« ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚
6. `specs`: å…ƒã®å•†å“ã«å«ã¾ã‚Œã‚‹`specs`ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ãã®ã¾ã¾ç¶­æŒã—ã¦ãã ã•ã„ã€‚

çµæœã‚’ã€ä»¥ä¸‹ã®æœ€çµ‚JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

ã€æœ€çµ‚å‡ºåŠ›JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
{{
  "recommended_products": [
    {{
      "rank": 1,
      "recommendation_reason": "ãªãœã“ã®å•†å“ãŒãŠã™ã™ã‚ãªã®ã‹ã€å…·ä½“çš„ãªç†ç”±ã€‚",
      "id": "product-a-xxxx",
      "name": "å•†å“A",
      "price": 79800,
      "description": "å•†å“ã®èª¬æ˜",
      "specs": {{ "æœ¬ä½“é‡é‡": "150g", "ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤": "6.1ã‚¤ãƒ³ãƒ" }},
      "specifications": {{ "key": "value" }},
      "rating": 5,
      "reviewCount": 12345,
      "category": "smartphone",
      "tags": ["tag1", "tag2"],
      "source_urls": ["https://www.youtube.com/watch?v=..."]
    }}
  ]
}}
'''

            response = await model.generate_content_async([prompt])
            
            if not response or not response.text:
                raise ValueError("ç·æ‹¬AIãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç©ºã®å¿œç­”ãŒè¿”ã•ã‚Œã¾ã—ãŸã€‚ã‚»ãƒ¼ãƒ•ãƒ†ã‚£è¨­å®šã«ã‚ˆã‚‹ãƒ–ãƒ­ãƒƒã‚¯ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

            response_text = response.text.strip()
            match = re.search(r"```json\s*(\{.*\})\s*```", response_text, re.DOTALL)
            if match:
                response_text = match.group(1)
            
            final_json = json.loads(response_text)
            print("[ç·æ‹¬ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] æœ€çµ‚æ¨è–¦ãƒªã‚¹ãƒˆã®ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
            return final_json
        except Exception as e:
            error_message = f"æœ€çµ‚æ¨è–¦æ–‡ã®ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
            print(f"[ç·æ‹¬ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": error_message}

    async def summarize_videos_and_recommend(self, youtube_urls: list[str], limited_tags: List[str], keyword: str) -> dict:
        """Orchestrates YouTube video summarization and recommendation."""
        video_ids = [url.split("v=")[-1].split("&")[0] for url in youtube_urls]
        view_counts_map = await self._get_video_view_counts_async(video_ids)

        print(f"[ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼] {len(youtube_urls)}ä»¶ã®URLã®ä¸¦åˆ—å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
        tasks = [self._extract_product_info_from_video_async(url, limited_tags, keyword) for url in youtube_urls]
        results = await asyncio.gather(*tasks)

        print("\n--- å„ãƒ¯ãƒ¼ã‚«ãƒ¼ã®åˆ†æçµæœ ---")
        all_products_map = {}
        for url, summary_json in results:
            video_id = url.split("v=")[-1].split("&")[0]
            view_count = view_counts_map.get(video_id, 0)

            print(f"\n--- {url} (å†ç”Ÿæ•°: {view_count}) ---")
            print(json.dumps(summary_json, indent=2, ensure_ascii=False))
            
            if summary_json and "error" not in summary_json and "products" in summary_json:
                for product in summary_json["products"]:
                    product_name = product.get("name")
                    if not product_name:
                        continue

                    # Merge info if the same product is found in multiple videos
                    if product_name not in all_products_map:
                        # Sanitize product name to create a stable ID
                        sanitized_name = re.sub(r'[^a-zA-Z0-9]+', '-', product_name).lower().strip('-')
                        product["id"] = f"product-{sanitized_name}-{str(uuid.uuid4())[:8]}"
                        product["source_urls"] = [url]
                        product["source_review_counts"] = [view_count]
                        all_products_map[product_name] = product
                    else:
                        all_products_map[product_name]["source_urls"].append(url)
                        all_products_map[product_name]["source_review_counts"].append(view_count)
        
        all_products_list = list(all_products_map.values())

        if all_products_list:
            final_recommendation = await self._generate_final_recommendation_async(all_products_list)
            print("\n========================================")
            print("ğŸ† ç·æ‹¬ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹æœ€çµ‚æ¨è–¦ãƒªã‚¹ãƒˆ ğŸ†")
            print("========================================")
            print(json.dumps(final_recommendation, indent=2, ensure_ascii=False))
            return final_recommendation
        else:
            print("\nåˆ†æã§ãã‚‹å•†å“æƒ…å ±ãŒãªã‹ã£ãŸãŸã‚ã€æœ€çµ‚æ¨è–¦ã¯è¡Œã„ã¾ã›ã‚“ã§ã—ãŸã€‚")
            return {"recommended_products": []} # Return empty list if no products found

    async def search_youtube_reviews_and_summarize(self, keyword: str, tags: List[str]) -> dict:
        """Searches YouTube for review videos based on keyword and tags, then summarizes them."""
        if not self.youtube:
            return {"error": "YouTube APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚YouTubeæ¤œç´¢ã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚"}

        # AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå•†å“é¸ã³ã«é‡è¦–ã—ã¦ã„ã‚‹ãƒã‚¤ãƒ³ãƒˆã‚’æŠ½å‡º
        try:
            model = GenerativeModel("gemini-2.5-flash-lite")
            
            # 1. keywordã‹ã‚‰YouTubeæ¤œç´¢ã«æœ‰åŠ¹ãªãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
            keyword_extraction_prompt = f'''ä»¥ä¸‹ã®æ–‡ç« ã‹ã‚‰ã€YouTubeæ¤œç´¢ã«æœ€ã‚‚é©ã—ãŸçŸ­ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆ2ã€œ3èªç¨‹åº¦ï¼‰ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
            ä¾‹1: "æœ€æ–°ã®ãƒã‚¤ã‚ºã‚­ãƒ£ãƒ³ã‚»ãƒªãƒ³ã‚°æ©Ÿèƒ½ä»˜ããƒ¯ã‚¤ãƒ¤ãƒ¬ã‚¹ã‚¤ãƒ¤ãƒ›ãƒ³" -> "ãƒ¯ã‚¤ãƒ¤ãƒ¬ã‚¹ã‚¤ãƒ¤ãƒ›ãƒ³ ãƒã‚¤ã‚ºã‚­ãƒ£ãƒ³ã‚»ãƒªãƒ³ã‚°"
            ä¾‹2: "ä¸€äººæš®ã‚‰ã—å‘ã‘ã®å°å‹å†·è”µåº«" -> "å°å‹å†·è”µåº« ä¸€äººæš®ã‚‰ã—"
            ä¾‹3: "ã‚½ãƒ‹ãƒ¼ã®ãƒ˜ãƒƒãƒ‰ãƒ›ãƒ³ã€WH-1000XM5ã‚’è²·ãŠã†ã‹æ‚©ã‚“ã§ã„ã¾ã™ã€‚" -> "ã‚½ãƒ‹ãƒ¼ WH-1000XM5"

            æ–‡ç« : "{keyword}"
            '''
            keyword_response = await model.generate_content_async([keyword_extraction_prompt])
            if not keyword_response or not keyword_response.text:
                raise ValueError("AIãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºã®ç©ºã®å¿œç­”ãŒè¿”ã•ã‚Œã¾ã—ãŸã€‚")
            
            extracted_keyword = keyword_response.text.strip()
            print(f"[AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] æŠ½å‡ºã•ã‚ŒãŸæ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {extracted_keyword}")

            # 2. ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå•†å“é¸ã³ã«é‡è¦–ã—ã¦ã„ã‚‹ãƒã‚¤ãƒ³ãƒˆã‚’ã‚¿ã‚°ã‹ã‚‰é¸æŠ
            tag_selection_prompt = f'''ä»¥ä¸‹ã®ã‚¿ã‚°ã®ä¸­ã‹ã‚‰ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå•†å“é¸ã³ã«æœ€ã‚‚é‡è¦–ã—ã¦ã„ã‚‹ã¨æ€ã‚ã‚Œã‚‹ãƒã‚¤ãƒ³ãƒˆã‚’2ã¤ã ã‘é¸ã‚“ã§ã€ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
            ä¾‹: "ãƒ‡ã‚¶ã‚¤ãƒ³æ€§,ä¾¡æ ¼"

            ã‚¿ã‚°: {', '.join(tags)}
            '''
            tag_response = await model.generate_content_async([tag_selection_prompt])
            if not tag_response or not tag_response.text:
                raise ValueError("AIãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã‚¿ã‚°é¸æŠã®ç©ºã®å¿œç­”ãŒè¿”ã•ã‚Œã¾ã—ãŸã€‚")
            
            selected_tags_str = tag_response.text.strip()
            selected_tags = [tag.strip() for tag in selected_tags_str.split(',') if tag.strip()]
            
            if not selected_tags:
                limited_tags = random.sample(tags, 2) if len(tags) > 2 else tags
            else:
                limited_tags = selected_tags[:2] # ä¸Šä½2ã¤ã‚’ä½¿ç”¨
            
            print(f"[AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé‡è¦–ã™ã‚‹ãƒã‚¤ãƒ³ãƒˆ: {', '.join(limited_tags)}")

        except Exception as e:
            print(f"[AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºã¾ãŸã¯é‡è¦–ãƒã‚¤ãƒ³ãƒˆã®æŠ½å‡ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            extracted_keyword = keyword # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ä½¿ç”¨
            limited_tags = random.sample(tags, 2) if len(tags) > 2 else tags

        search_query = f"{extracted_keyword} {' '.join(limited_tags)} ãƒ¬ãƒ“ãƒ¥ãƒ¼" # e.g., "ãƒ¯ã‚¤ãƒ¤ãƒ¬ã‚¹ã‚¤ãƒ¤ãƒ›ãƒ³ ãƒã‚¤ã‚ºã‚­ãƒ£ãƒ³ã‚»ãƒªãƒ³ã‚° ãƒ‡ã‚¶ã‚¤ãƒ³æ€§ ä¾¡æ ¼ ãƒ¬ãƒ“ãƒ¥ãƒ¼"
        print(f"[YouTubeæ¤œç´¢] æ¤œç´¢ã‚¯ã‚¨ãƒª: {search_query}")

        try:
            search_response = await asyncio.to_thread(
                self.youtube.search().list,
                q=search_query,
                part="id,snippet",
                type="video",
                maxResults=3, # Max 3 videos
                regionCode="JP",
                relevanceLanguage="ja"
            )
            response_data = search_response.execute()

            youtube_urls = []
            for item in response_data.get("items", []):
                video_id = item["id"]["videoId"]
                youtube_urls.append(f"https://www.youtube.com/watch?v={video_id}")
            
            if not youtube_urls:
                print("[YouTubeæ¤œç´¢] é–¢é€£ã™ã‚‹YouTubeãƒ¬ãƒ“ãƒ¥ãƒ¼å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                return {"error": "é–¢é€£ã™ã‚‹YouTubeãƒ¬ãƒ“ãƒ¥ãƒ¼å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"}

            print(f"[YouTubeæ¤œç´¢] {len(youtube_urls)}ä»¶ã®å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚è¦ç´„å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
            return await self.summarize_videos_and_recommend(youtube_urls, limited_tags, keyword)

        except Exception as e:
            print(f"[YouTubeæ¤œç´¢] YouTubeæ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return {"error": f"YouTubeæ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"}

    _VEO_PROMPT_TEMPLATE = """[PRODUCT A]:< {product_a_summary} >
[PRODUCT B]:< {product_b_summary} >

**Core Concept:** A dynamic, 8-second, seamless loop of a 3D animated battle. This video is intended as a background element for a mobile app that compares two products, provided as text inputs [PRODUCT A] and [PRODUCT B].

**Style & Mood:**
*   **Visual Style:** Vibrant, high-quality 3D animation. The aesthetic is inspired by the cheerful and dynamic style of popular Japanese battle games, but must be a **unique and original creation**. The look should be cute, pop, and playful.
*   **Color Palette:** The overall scene uses a bright, pastel-based color palette. Turquoise (#00C6C2) and gold (#FFD700) are used as key accent colors, creating a dynamic and appealing color scheme reminiscent of a modern trading card game.
*   **Atmosphere:** Fun, energetic, and friendly competition. The action is cartoonish and joyful, completely avoiding any realistic or intense violence.

**Sound Design:**
*   Add cheerful, upbeat electronic background music that loops seamlessly with the video.
*   Include playful and lighthearted sound effects for the actions (e.g., 'swoosh', 'zap', 'poof').
*   Incorporate cute giggling or cheering sounds from the characters occasionally, especially during expressive moments.

**Scene Description:**
*   **Setting:** A minimalist and brightly lit circular battle arena. The stage's theme should be creatively and subtly inspired by the general category of the two products being compared (e.g., a cyber-themed stage for electronics, a giant kitchen-themed stage for food items).
*   **Characters:**
    *   **Character A:** An anthropomorphic mascot representation of **[PRODUCT A]**. The character's design is the product itself, brought to life with cute arms and legs.
    *   **Character B:** An anthropomorphic mascot representation of **[PRODUCT B]**. Similarly, its design is the product itself with arms and legs.
    *   **Facial Expressions:** Both characters have large, innocent, and expressive eyes and a friendly smile. The style should be universally appealing and cute, **without directly copying any existing famous characters.**
*   **Action (8-Second Loop):**
    *   The two mascot characters engage in a continuous, dance-like battle.
    *   **"Merit" Attacks:** Their attacks are cartoonish, non-violent, and playfully inspired by the strengths and benefits of their respective products.
    *   **"Demerit" Reactions:** When a character is "hit" by an opponent's attack, it reacts in a comical and exaggerated way, such as being briefly knocked off-balance or spinning with dizzy stars.
    *   The action is fluid with nimble dodges and fun effects like sparkles and colorful puffs of smoke.
    *   The 8-second sequence must start and end in a similar, neutral confrontational pose to ensure a perfect, seamless loop.

**Constraints:**
*   **Originality and IP:** The generated characters, stage, and effects must be **original designs**. They must not resemble or infringe upon the intellectual property of any existing brands, franchises, or specific characters. The style should be *inspired by* the genre, not a direct copy.
*   **No Text:** Absolutely no text, letters, or numbers are to be rendered in the video.
*   **Seamless Loop:** The final output must be a perfectly seamless 8-second loop.
*   **High Frame Rate:** Render at a high frame rate for ultra-smooth motion.
*   **Positive Expressions:** The characters' facial expressions should always be positive and cute, avoiding any signs of genuine pain or distress.
""" 

    def _create_veo_prompt_for_battle(self, product_a_summary: str, product_b_summary: str) -> str:
        """
        Generates an optimized Veo3 prompt based on two product summaries.
        """
        print("[VEOã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] å‹•ç”»ç”Ÿæˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆä¸­...")
        prompt = self._VEO_PROMPT_TEMPLATE.format(
            product_a_summary=product_a_summary,
            product_b_summary=product_b_summary
        )
        print("[VEOã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] å‹•ç”»ç”Ÿæˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
        return prompt.strip()

    async def _generate_video_async(self, prompt: str, session_id: str) -> dict:
        """Generates a video using Veo, polls for completion, and returns a signed URL."""
        print(f"[å‹•ç”»ç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] ã‚»ãƒƒã‚·ãƒ§ãƒ³ID: {session_id} ã®å‹•ç”»ç”Ÿæˆã‚’é–‹å§‹...")
        # --- Diagnostic Logging ---
        model_name_to_use = settings.VEO_MODEL_NAME
        print(f"[å‹•ç”»ç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] ä½¿ç”¨ã™ã‚‹è¨­å®šå€¤:")
        print(f"  - Project: {self.project_id}")
        print(f"  - Location: {self.location}")
        print(f"  - Model Name: {model_name_to_use}")
        # -------------------------
        if not self.genai_client:
            print("[å‹•ç”»ç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] ERROR: genai.ClientãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å‹•ç”»ç”Ÿæˆã‚’ä¸­æ­¢ã—ã¾ã™ã€‚")
            return {"status": "error", "message": "genai.ClientãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"}

        try:
            # 1. Define the dynamic GCS output path for Veo
            current_date_str = datetime.now(timezone(timedelta(hours=+9))).strftime("%Y-%m-%d")
            gcs_blob_folder = f"{current_date_str}/{session_id}"
            output_gcs_folder_uri = f'gs://{settings.GCS_BUCKET_NAME}/{gcs_blob_folder}'
            print(f'[{session_id}] Veoå‡ºåŠ›å…ˆ: {output_gcs_folder_uri}')

            # 2. Start the video generation operation
            veo_operation = await asyncio.to_thread(
                self.genai_client.models.generate_videos,
                model=getattr(settings, 'VEO_MODEL_NAME', "veo-3.0-fast-generate-001"),
                prompt=prompt,
                config=genai_types.GenerateVideosConfig(
                    person_generation='dont_allow',
                    aspect_ratio='16:9',
                    output_gcs_uri=output_gcs_folder_uri,
                ),
            )
            print(f'[{session_id}] Veo operation é–‹å§‹: {veo_operation.name}')

            # 3. Poll the operation for completion
            while not veo_operation.done:
                await asyncio.sleep(5) # Poll every 5 seconds
                veo_operation = await asyncio.to_thread(
                    self.genai_client.operations.get, veo_operation
                )
                print(f"[{session_id}] ãƒãƒ¼ãƒªãƒ³ã‚°ä¸­...å®Œäº†ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {veo_operation.done}")

            print(f'[{session_id}] Veoæ“ä½œå®Œäº†ã€‚ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {veo_operation.done}')

            # 4. Process the result
            if veo_operation.error:
                error_message_detail = getattr(veo_operation.error, 'message', str(veo_operation.error))
                raise Exception(f"Veoå‹•ç”»ç”ŸæˆãŒå¤±æ•—ã—ã¾ã—ãŸ: {error_message_detail}")

            if not (veo_operation.response and veo_operation.response.generated_videos):
                raise Exception("Veoãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«å‹•ç”»ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

            # 5. Get GCS URI from response and generate a signed URL
            generated_video_info = veo_operation.response.generated_videos[0]
            veo_provided_gcs_uri = generated_video_info.video.uri
            print(f'[{session_id}] å‹•ç”»ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å—ä¿¡ã€‚Veo GCS URI: {veo_provided_gcs_uri}')

            parsed_uri = urlparse(veo_provided_gcs_uri)
            blob_name = parsed_uri.path.lstrip('/')
            
            signed_url = await self._generate_signed_url_async(blob_name, settings.GCS_BUCKET_NAME)

            if not signed_url:
                raise Exception("ç½²åä»˜ãURLã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

            return {
                "status": "success",
                "message": "å‹•ç”»ã®ç”Ÿæˆã¨ç½²åä»˜ãURLã®å–å¾—ã«æˆåŠŸã—ã¾ã—ãŸã€‚",
                "gcs_signed_url": signed_url,
            }

        except Exception as e:
            print(f"[å‹•ç”»ç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] å‹•ç”»ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return {"status": "error", "message": str(e), "gcs_signed_url": None}

    async def _generate_signed_url_async(self, blob_name: str, bucket_name: str) -> Optional[str]:
        """Generates a signed URL for a GCS blob, using impersonation if needed."""
        try:
            blob = self.storage_client.bucket(bucket_name).blob(blob_name)
            
            # Determine credentials for signing
            signing_creds = self.credentials

            # If no file-based credentials are provided, use impersonation
            if not signing_creds:
                signer_email = settings.GCP_IAM_SERVICE_ACCOUNT_EMAIL
                if not signer_email:
                    raise ValueError(
                        "GCP_IAM_SERVICE_ACCOUNT_EMAIL environment variable is not set. "
                        "It is required for signing URLs in a Cloud Run environment."
                    )
                
                print(f"ç½²åã«ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ'{signer_email}'ã®æ¨©é™å€Ÿç”¨ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                # Get default credentials from the environment (the runtime service account)
                default_creds, _ = default()
                # Create impersonated credentials
                signing_creds = impersonated_credentials.Credentials(
                    source_credentials=default_creds,
                    target_principal=signer_email,
                    target_scopes=["https://www.googleapis.com/auth/iam"], # Scope for signing
                )

            signed_url = await asyncio.to_thread(
                blob.generate_signed_url,
                version="v4",
                expiration=timedelta(hours=1),
                method="GET",
                credentials=signing_creds,
            )
            print(f"GCS URI gs://{bucket_name}/{blob_name} ã®ç½²åä»˜ãURLã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚")
            return signed_url
        except Exception as e:
            print(f"ç½²åä»˜ãURLã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    async def generate_product_battle(self, product_name_1: str, product_name_2: str) -> dict:
        """Generates a mock product battle description."""
        print(f"[å¯¾æ±ºã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] ã€Œ{product_name_1}ã€vsã€Œ{product_name_2}ã€ã®å¯¾æ±ºã‚·ãƒŠãƒªã‚ªã‚’ç”Ÿæˆä¸­...")
        battle_id = f"battle-{uuid.uuid4()}"
        try:
            model = GenerativeModel("gemini-2.5-flash")
            prompt = f'''ã‚ãªãŸã¯ã€2ã¤ã®è£½å“ã®æ“¬äººåŒ–ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨ã—ã¦ã€äº’ã„ã®é•·æ‰€ã‚’ã‚¢ãƒ”ãƒ¼ãƒ«ã—åˆã†å¯¾æ±ºå½¢å¼ã®ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã†è„šæœ¬å®¶ã§ã™ã€‚

è£½å“1: ã€Œ{product_name_1}ã€
è£½å“2: ã€Œ{product_name_2}ã€

ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦ã€ä¸¡è£½å“ãŒäº’ã„ã«3ã¤ã®ãƒã‚¤ãƒ³ãƒˆã§å¼·ã¿ã‚’ä¸»å¼µã—åˆã†ã€é­…åŠ›çš„ãªèª¬æ˜æ–‡ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

# ãƒ«ãƒ¼ãƒ«
- å„è£½å“ã®èª¬æ˜æ–‡ã¯3ã¤ã®ç‹¬ç«‹ã—ãŸæ–‡ç« ï¼ˆæ–‡å­—åˆ—ï¼‰ã®é…åˆ—ã«ã—ã¦ãã ã•ã„ã€‚
- å„æ–‡ç« ã¯ã€ç›¸æ‰‹ã‚’æ„è­˜ã—ã¤ã¤ã‚‚ã€è‡ªèº«ã®å…·ä½“çš„ãªç‰¹å¾´ã‚„ãƒ¡ãƒªãƒƒãƒˆã‚’åŠ›å¼·ãã‚¢ãƒ”ãƒ¼ãƒ«ã™ã‚‹ã‚‚ã®ã«ã—ã¦ãã ã•ã„ã€‚
- ãƒ¦ãƒ¼ãƒ¢ã‚¢ã‚„å°‘ã—ã®æŒ‘ç™ºã‚’å«ã‚“ã§ã‚‚æ§‹ã„ã¾ã›ã‚“ãŒã€å†…å®¹ã¯æŠ€è¡“çš„ãªäº‹å®Ÿã«å³ã—ã¦ãã ã•ã„ã€‚
- å‡ºåŠ›ã¯å¿…ãšä»¥ä¸‹ã®JSONå½¢å¼ã«å¾“ã£ã¦ãã ã•ã„ã€‚

# å‡ºåŠ›JSONã‚¹ã‚­ãƒ¼ãƒ
{{
  "product1_description": [
    "è£½å“1ã®å¼·ã¿1ã‚’ã‚¢ãƒ”ãƒ¼ãƒ«ã™ã‚‹èª¬æ˜æ–‡ã€‚",
    "è£½å“1ã®å¼·ã¿2ã‚’ã‚¢ãƒ”ãƒ¼ãƒ«ã™ã‚‹èª¬æ˜æ–‡ã€‚",
    "è£½å“1ã®å¼·ã¿3ã‚’ã‚¢ãƒ”ãƒ¼ãƒ«ã™ã‚‹èª¬æ˜æ–‡ã€‚"
  ],
  "product2_description": [
    "è£½å“2ã®å¼·ã¿1ã‚’ã‚¢ãƒ”ãƒ¼ãƒ«ã™ã‚‹èª¬æ˜æ–‡ã€‚",
    "è£½å“2ã®å¼·ã¿2ã‚’ã‚¢ãƒ”ãƒ¼ãƒ«ã™ã‚‹èª¬æ˜æ–‡ã€‚",
    "è£½å“2ã®å¼·ã¿3ã‚’ã‚¢ãƒ”ãƒ¼ãƒ«ã™ã‚‹èª¬æ˜æ–‡ã€‚"
  ]
}}
'''

            response = await model.generate_content_async([prompt])
            
            if not response or not response.text:
                raise ValueError("AIãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç©ºã®å¿œç­”ãŒè¿”ã•ã‚Œã¾ã—ãŸã€‚")

            response_text = response.text.strip()
            json_string = response_text

            match = re.search(r"```json\s*(\{.*\})\s*```", response_text, re.DOTALL)
            if match:
                json_string = match.group(1)

            try:
                ai_response = json.loads(json_string)
            except json.JSONDecodeError as e:
                print(f"[å¯¾æ±ºã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] ERROR: JSONã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ¢ãƒ‡ãƒ«ã®ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹: '''{response_text}'''")
                raise ValueError(f"ãƒ¢ãƒ‡ãƒ«ãŒæœ‰åŠ¹ãªJSONã‚’è¿”ã—ã¾ã›ã‚“ã§ã—ãŸ: {e}")

            # --- AI Agent 2: Video Prompt Generation ---
            product1_full_description = " ".join(ai_response.get("product1_description", []))
            product2_full_description = " ".join(ai_response.get("product2_description", []))
            
            video_prompt = self._create_veo_prompt_for_battle(
                product_a_summary=f"{product_name_1}: {product1_full_description}",
                product_b_summary=f"{product_name_2}: {product2_full_description}"
            )

            # --- AI Agent 3: Video Generation ---
            video_generation_result = await self._generate_video_async(
                prompt=video_prompt,
                session_id=battle_id
            )

            video_url = video_generation_result.get("gcs_signed_url")
            # Use placeholder if generation fails
            if video_generation_result.get("status") != "success" or not video_url:
                video_url = "https://storage.googleapis.com/public-dds-react-camp-machu/battle_movies/Fighting_Game_Product_Battle_Video.mp4"

            # Add static data and the new video prompt to the response
            final_response = {
                "id": battle_id,
                "product1_id": "dummy-prod-1",
                "product1_name": product_name_1,
                "product1_description": ai_response.get("product1_description", []),
                "product2_id": "dummy-prod-2",
                "product2_name": product_name_2,
                "product2_description": ai_response.get("product2_description", []),
                "video_prompt": video_prompt,
                "video_url": video_url,
            }
            print(f"[å¯¾æ±ºã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] å¯¾æ±ºã‚·ãƒŠãƒªã‚ªã¨å‹•ç”»ã®ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
            return final_response

        except Exception as e:
            print(f"[å¯¾æ±ºã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] å¯¾æ±ºã‚·ãƒŠãƒªã‚ªã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            raise ValueError(f"å¯¾æ±ºã‚·ãƒŠãƒªã‚ªã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    async def recommend_products(
        self, 
        user_preferences: Dict,
        product_catalog: List[Product]
    ) -> List[Product]:
        """Recommends products based on user preferences."""
        # This is a stub implementation.
        # Actual implementation will use a recommendation algorithm.
        print(f"Recommending products based on: {user_preferences}")
        return product_catalog[:2] # Return first two products as a mock recommendation

class MockAnalyzeNeedsService: 
    """Mock version of AnalyzeNeedsService for development and testing."""

    async def generate_chat_response(
        self, 
        message: str, 
        context: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """Generates a mock chat response."""
        print(f"Mock chat response for message: {message}")
        if "æ¯”è¼ƒ" in message:
            return {
                "message": "æ‰¿çŸ¥ã„ãŸã—ã¾ã—ãŸã€‚æ¯”è¼ƒãƒšãƒ¼ã‚¸ã«ç§»å‹•ã—ã¾ã™ã€‚",
                "navigateTo": "/comparison"
            }
        return {
            "message": f"ã“ã‚Œã¯ã€Œ{message}ã€ã«å¯¾ã™ã‚‹ãƒ¢ãƒƒã‚¯å¿œç­”ã§ã™ã€‚",
            "navigateTo": None
        }

    async def analyze_needs_and_generate_images(self, product_category: str) -> Dict[str, Any]:
        """Generates mock user archetypes with placeholder images."""
        print(f"Mock analysis for product category: {product_category}")
        await asyncio.sleep(1)  # Simulate network delay
        return {
            "user_archetypes": [
                {
                    "id": str(uuid.uuid4()),
                    "name": "ãƒ‡ã‚¶ã‚¤ãƒ³é‡è¦–ã‚¿ã‚¤ãƒ—",
                    "description": "è¦‹ãŸç›®ã®ç¾ã—ã•ã¨ã€ç©ºé–“ã«èª¿å’Œã™ã‚‹ãƒ‡ã‚¶ã‚¤ãƒ³ã‚’æœ€å„ªå…ˆã€‚",
                    "characteristics": ["ç¾ã—ã„ãƒ‡ã‚¶ã‚¤ãƒ³", "é«˜ç´šæ„Ÿ", "ã‚¤ãƒ³ãƒ†ãƒªã‚¢æ€§"],
                    "sampleProducts": ["ãƒãƒ«ãƒŸãƒ¥ãƒ¼ãƒ€ ã‚¶ãƒ»ãƒˆãƒ¼ã‚¹ã‚¿ãƒ¼", "ãƒ€ã‚¤ã‚½ãƒ³ Supersonic Ionic"],
                    "imageUrl": "https://storage.googleapis.com/public-dds-react-camp-machu/archetype_images/sample/design.png"
                },
                {
                    "id": str(uuid.uuid4()),
                    "name": "æ©Ÿèƒ½æ€§ãƒ»å¤šæ©Ÿèƒ½ã‚¿ã‚¤ãƒ—",
                    "description": "ä¸€å°ã§ä½•å½¹ã‚‚ã“ãªã™ã€æœ€æ–°æŠ€è¡“ã¨å¤šæ©Ÿèƒ½æ€§ã‚’æ±‚ã‚ã‚‹ã€‚",
                    "characteristics": ["å¤šæ©Ÿèƒ½", "æœ€æ–°æŠ€è¡“", "é«˜æ€§èƒ½"],
                    "sampleProducts": ["ãƒ‘ãƒŠã‚½ãƒ‹ãƒƒã‚¯ ãƒ“ã‚¹ãƒˆãƒ­", "ãƒ«ãƒ³ãƒ j7+"],
                    "imageUrl": "https://storage.googleapis.com/public-dds-react-camp-machu/archetype_images/sample/multi-function.png"
                }
            ]
        }

def get_analyze_needs_service() -> AnalyzeNeedsService | MockAnalyzeNeedsService:
    """
    Factory function to get the appropriate AnalyzeNeedsService instance
    based on the environment settings.
    """
    if settings.ENVIRONMENT == "development":
        print("Using MockAnalyzeNeedsService for development environment.")
        return MockAnalyzeNeedsService()
    
    # In a production environment, you would initialize the real service
    # with credentials and other necessary configurations.
    print("Using real AnalyzeNeedsService.")
    return AnalyzeNeedsService(
        project_id=settings.GCP_PROJECT_ID,
        location=settings.VERTEX_AI_MODEL_REGION
    )
